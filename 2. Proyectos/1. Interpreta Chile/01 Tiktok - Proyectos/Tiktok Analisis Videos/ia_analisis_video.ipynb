{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import io\n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client      = vision.ImageAnnotatorClient.from_service_account_file('gcp_key.json')\n",
    "\n",
    "# image_path  = r'video_frames\\7481308222805019947\\frame_3.jpg'\n",
    "\n",
    "# image_paths =  [r'video_frames\\7481308222805019947\\frame_1.jpg',\n",
    "#                 r'video_frames\\7481308222805019947\\frame_2.jpg',\n",
    "#                 r'video_frames\\7481308222805019947\\frame_3.jpg',\n",
    "#                 r'video_frames\\7481308222805019947\\frame_4.jpg',\n",
    "#                 r'video_frames\\7481308222805019947\\frame_5.jpg']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagen_analisis (image_path):\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    with open(image_path,\"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    \n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "\n",
    "#01 Texto\n",
    "    response  = client.text_detection(image=image)\n",
    "    textos    = response.text_annotations\n",
    "\n",
    "    try:\n",
    "        text_block = [text.description for text in textos][0].replace(\"\\n\",\" \")\n",
    "    except:\n",
    "        text_block = \" \"\n",
    "    \n",
    "    df_texto = pd.DataFrame({\"Texto\": [text_block],\"Image\": [image_path],\"Categoria\": [\"Texto\"]})\n",
    "\n",
    "\n",
    "#02 Objects\n",
    "    objects = client.object_localization(image=image).localized_object_annotations\n",
    "    filtered_objects = {obj.name: obj.score for obj in objects if obj.score > 0.65}        \n",
    "    df_objeto = pd.DataFrame(filtered_objects.items(), columns=['Name', 'Score']).assign(Image=image_path,Categoria = 'Objetos')\n",
    "\n",
    "\n",
    "#03 Labels\n",
    "    response = client.label_detection(image=image)\n",
    "    labels   = response.label_annotations\n",
    "    filtered_labels = {label.description: label.score for label in labels if label.score > 0.75}\n",
    "    df_labels = pd.DataFrame(filtered_labels.items(), columns=['Name', 'Score']).assign(Image=image_path,Categoria = 'Etiquetas')\n",
    "\n",
    "\n",
    "#04 Faces\n",
    "    response = client.face_detection(image=image)\n",
    "    faces    = response.face_annotations\n",
    "\n",
    "    likelihood_name = (\"UNKNOWN\",\"VERY_UNLIKELY\",\"UNLIKELY\",\"POSSIBLE\",\"LIKELY\",\"VERY_LIKELY\",)\n",
    "\n",
    "    faces_data = []\n",
    "\n",
    "    for i, face in enumerate(faces):\n",
    "        face_info = {\n",
    "            \"Rostro\": f\"Rostro {i+1}\",\n",
    "            \"Detection Confidence\": face.detection_confidence,\n",
    "            \"Anger Likelihood\": likelihood_name[getattr(face, \"anger_likelihood\", 0)], \n",
    "            \"Joy Likelihood\": likelihood_name[getattr(face, \"joy_likelihood\", 0)]\n",
    "        }\n",
    "        faces_data.append(face_info)\n",
    "\n",
    "    df_faces = pd.DataFrame(faces_data)\n",
    "    df_faces[\"Image\"] = image_path\n",
    "    df_faces[\"Categoria\"] = \"Faces\"\n",
    "\n",
    "##########################\n",
    "    df_description = pd.concat([df_labels,df_texto,df_objeto])\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Tiempo de ejecución: {execution_time:.4f} segundos\")\n",
    "\n",
    "    return df_faces,df_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJECUCION DE LA FUNCION PRINCIPAL / LOOP EN LOS FRAMES DENTRO DE CADA UNA DE SUS CARPETAS\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Carpeta principal\n",
    "base_folder = \"video_frames\"\n",
    "\n",
    "# Iterar sobre cada subcarpeta dentro de 'video_frames'\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "\n",
    "for subfolder in os.listdir(base_folder):\n",
    "    subfolder_path = os.path.join(base_folder, subfolder)\n",
    "    \n",
    "    # Verificar si es un directorio\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Buscar archivos .jpg dentro de la subcarpeta\n",
    "        image_files = sorted(glob.glob(os.path.join(subfolder_path, \"frame_*.jpg\")))\n",
    "\n",
    "\n",
    "        ruta_carpeta = r'video_results'\n",
    "\n",
    "        # Procesar las imágenes\n",
    "        faces_images = pd.DataFrame() \n",
    "        descr_images = pd.DataFrame()\n",
    "\n",
    "        for image_path in image_files:\n",
    "            nombre_base = os.path.basename(os.path.dirname(image_path))\n",
    "            img_faces,img_descrip =  imagen_analisis(image_path=image_path)        \n",
    "\n",
    "            faces_images = pd.concat([faces_images,img_faces])\n",
    "            descr_images = pd.concat([descr_images,img_descrip])\n",
    "\n",
    "        ###\n",
    "        faces_images   = faces_images.assign(Video= nombre_base)\n",
    "        try:\n",
    "            faces_images   = faces_images[faces_images['Detection Confidence'] > 0.95] #Seleccion de probabilidad de mas del 95%\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ###\n",
    "        descr_images   = descr_images.assign(Video = nombre_base)   \n",
    "        try:\n",
    "            descr_images.fillna({'Score':1},inplace=True)\n",
    "            descr_images = descr_images[descr_images['Score'] > 0.85]\n",
    "            descr_images = descr_images.drop_duplicates(subset=['Name','Texto']).sort_values(by=['Categoria','Score'],ascending=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        carpeta_archivo = os.path.join(ruta_carpeta,nombre_base) \n",
    "        os.makedirs(carpeta_archivo, exist_ok=True)\n",
    "\n",
    "        \n",
    "        # ruta_faces = os.path.join(carpeta_archivo, f\"faces_{nombre_base}.xlsx\")\n",
    "        # ruta_descr = os.path.join(carpeta_archivo, f\"descriptions_{nombre_base}.xlsx\")\n",
    "        \n",
    "        # faces_images.to_excel(ruta_faces, index=False)\n",
    "        # descr_images.to_excel(ruta_descr, index=False)\n",
    "\n",
    "        ruta_resultados = os.path.join(carpeta_archivo, f\"faces_{nombre_base}.xlsx\") \n",
    "        \n",
    "        with pd.ExcelWriter(ruta_resultados, engine=\"openpyxl\") as writer:\n",
    "            faces_images.to_excel(writer, sheet_name=\"Faces\", index=False)\n",
    "            descr_images.to_excel(writer, sheet_name=\"Descriptions\", index=False)\n",
    "                    \n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time    \n",
    "print(f\"-Tiempo de ejecución de todas las imagenes: {execution_time:.4f} segundos\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo consolidado guardado en: video_results\\consolidado.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Directorio raíz donde están las subcarpetas con archivos Excel\n",
    "directorio_base = r'video_results'\n",
    "\n",
    "\n",
    "# Buscar todos los archivos .xlsx en subcarpetas\n",
    "archivos_excel = glob.glob(os.path.join(directorio_base, \"**\", \"faces_*.xlsx\"), recursive=True)\n",
    "\n",
    "# Diccionario para almacenar los DataFrames agrupados por nombre de hoja\n",
    "dataframes_por_hoja = {}\n",
    "\n",
    "# Leer cada archivo Excel\n",
    "for archivo in archivos_excel:\n",
    "    xls = pd.ExcelFile(archivo, engine=\"openpyxl\")  # Abrir archivo\n",
    "    for hoja in xls.sheet_names:  # Recorrer cada hoja\n",
    "        df = pd.read_excel(xls, sheet_name=hoja)  # Leer hoja\n",
    "        df[\"Archivo\"] = os.path.basename(archivo)  # Agregar columna de origen\n",
    "\n",
    "        # Agregar el DataFrame a la lista correspondiente a su hoja\n",
    "        if hoja not in dataframes_por_hoja:\n",
    "            dataframes_por_hoja[hoja] = []\n",
    "        dataframes_por_hoja[hoja].append(df)\n",
    "\n",
    "# Crear un archivo consolidado con dos hojas\n",
    "ruta_consolidado = os.path.join(directorio_base, \"analisis_video_tiktok.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(ruta_consolidado, engine=\"openpyxl\") as writer:\n",
    "    for hoja, lista_df in dataframes_por_hoja.items():\n",
    "        df_concatenado = pd.concat(lista_df, ignore_index=True).drop(columns='Video')\n",
    "        df_concatenado.to_excel(writer, sheet_name=hoja, index=False)\n",
    "\n",
    "print(f\"Archivo consolidado guardado en: {ruta_consolidado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
